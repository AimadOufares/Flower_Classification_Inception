# ğŸŒ¸ Classification de 5 Types de Fleurs avec InceptionV3

**Projet Deep Learning â€“ AnnÃ©e universitaire 2025/2026**  
**Auteur : Aimad Oufares**  
**Master ISI â€“ UniversitÃ© Cadi Ayyad, Marrakech**

---

## ğŸ“˜ Description du Projet

Ce projet a pour objectif de dÃ©velopper un modÃ¨le de **Deep Learning** capable de classifier **5 types de fleurs** Ã  partir dâ€™images, en utilisant le **Transfer Learning** avec lâ€™architecture **InceptionV3**.  

Le projet couvre un pipeline complet de classification dâ€™images :

1. **Exploration et analyse du dataset**  
2. **PrÃ©traitement des images et gÃ©nÃ©ration de donnÃ©es augmentÃ©es**  
3. **Construction et entraÃ®nement dâ€™un modÃ¨le baseline**  
4. **Fine-tuning du modÃ¨le pour amÃ©liorer les performances**  
5. **Ã‰valuation et gÃ©nÃ©ration de rapports visuels et textuels**  

---

## ğŸ“‚ Dataset

Le dataset contient environ **5 000 images** rÃ©parties en **5 classes** de fleurs :

    flower_images/
            â”œâ”€â”€ Lilly
            â”œâ”€â”€ Lotus
            â”œâ”€â”€ Orchid
            â”œâ”€â”€ Sunflower
            â””â”€â”€ Tulip


- Images Ã©quilibrÃ©es et de bonne qualitÃ©  
- IdÃ©al pour le Transfer Learning  

ğŸ“ Source Kaggle : [5 Flower Types Classification Dataset](https://www.kaggle.com/datasets/kausthubkannan/5-flower-types-classification-dataset)

---

## ğŸ§  Objectifs d'Apprentissage

- Comprendre et appliquer le **Transfer Learning**  
- Utiliser une architecture avancÃ©e (**InceptionV3**)  
- PrÃ©parer un pipeline complet de classification dâ€™images  
- ImplÃ©menter le **fine-tuning** pour optimiser les performances  
- Ã‰valuer un modÃ¨le avec prÃ©cision, matrice de confusion et rapport de classification  
- Visualiser les rÃ©sultats et comparer baseline vs fine-tuning  

---

## ğŸ› ï¸ Technologies UtilisÃ©es

- **Python 3**  
- **TensorFlow / Keras**  
- **NumPy, Pandas**  
- **Matplotlib / Seaborn**  
- **scikit-learn**  
- **Google Colab (GPU recommandÃ©)**  

---

## ğŸ“ Structure du Projet

```

Flower_Classification_Inception/
â”‚
â”œâ”€â”€ code/
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb   # Analyse et visualisation du dataset
â”‚   â”œâ”€â”€ 02_baseline_model.ipynb     # EntraÃ®nement du modÃ¨le baseline
â”‚   â”œâ”€â”€ 03_fine_tuning.ipynb        # Fine-tuning du modÃ¨le
â”‚   â””â”€â”€ 04_evaluation.ipynb         # Ã‰valuation et gÃ©nÃ©ration de rapports
â”‚
â”œâ”€â”€ data/                            # Dataset (ignorÃ© dans Git)
â”‚   â””â”€â”€ .gitkeep
â”œâ”€â”€ models/                          # ModÃ¨les sauvegardÃ©s
â”‚   â”œâ”€â”€ inception_baseline.h5
â”‚   â””â”€â”€ inception_finetuned.h5
â”œâ”€â”€ reports/                         # Graphiques et rapports
â”‚   â”œâ”€â”€ baseline_training_history.png
â”‚   â”œâ”€â”€ fine_tuning_history.png
â”‚   â”œâ”€â”€ compare_histories.png
â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â””â”€â”€ classification_report.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ .gitignore

````
---

## ğŸš€ **Installation & ExÃ©cution**

### 1. Cloner le projet

``` bash
git clone https://github.com/username/Flower_Classification_Inception.git
cd Flower_Classification_Inception
```

### 2. CrÃ©er un environnement virtuel

``` bash
python -m venv venv
source venv/bin/activate
```

### 3. Installer les dÃ©pendances

``` bash
pip install -r requirements.txt
```

------------------------------------------------------------------------


## ğŸ“Š RÃ©sultats attendus

* Graphiques dâ€™apprentissage (accuracy & loss) pour baseline et fine-tuning
* Matrice de confusion et rapport de classification (Precision, Recall, F1-score)
* Comparaison des performances baseline vs fine-tuning

---

## ğŸ’¡ AmÃ©liorations possibles

* Utiliser un **dataset plus grand** pour une meilleure gÃ©nÃ©ralisation
* ExpÃ©rimenter avec dâ€™autres architectures prÃ©-entraÃ®nÃ©es (ResNet, MobileNet, VGG)
* ImplÃ©menter **EarlyStopping** et **ReduceLROnPlateau** pour optimiser lâ€™entraÃ®nement
* Techniques avancÃ©es de **data augmentation**

---

## ğŸ‘¨â€ğŸ’» Auteur

**Aimad Oufares**
Master ISI â€“ UniversitÃ© Cadi Ayyad, Marrakech
Projet Deep Learning â€“ 2025/2026
