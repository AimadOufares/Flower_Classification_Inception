{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c455f9b-2077-41e2-addf-2ba7074772d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 03_fine_tuning.ipynb\n",
    "# Fine-tuning du modèle InceptionV3 sur les fleurs\n",
    "# ============================================================\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. Importations\n",
    "# ------------------------------------------------------------\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "680ec459-6e35-48dc-ab0e-6c580ce64846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset : ../data/flower_images\n",
      "Classes : ['Lilly', 'Lotus', 'Orchid', 'Sunflower', 'Tulip']\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 2. Chemins et dossiers\n",
    "# ------------------------------------------------------------\n",
    "DATASET_PATH = \"../data/flower_images\"\n",
    "MODEL_DIR = \"../models\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "MODEL_BASELINE_PATH = os.path.join(MODEL_DIR, \"inception_baseline.h5\")\n",
    "\n",
    "# Nom des fichiers avec timestamp pour versionner\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "MODEL_FINETUNED_PATH = os.path.join(MODEL_DIR, f\"inception_finetuned_{timestamp}.h5\")\n",
    "HISTORY_FINETUNE_PATH = os.path.join(MODEL_DIR, f\"history_finetune_{timestamp}.pkl\")\n",
    "\n",
    "print(\"Dataset :\", DATASET_PATH)\n",
    "print(\"Classes :\", os.listdir(DATASET_PATH))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65f6261c-4fb3-4ab2-995a-3109794d2566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 3. Paramètres\n",
    "# ------------------------------------------------------------\n",
    "IMG_SIZE = (299, 299)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 25\n",
    "LR = 1e-5  # très faible pour fine-tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b6e2199-1e7f-4c73-a5b7-d0b636943fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 images belonging to 5 classes.\n",
      "Found 1000 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 4. Générateurs de données\n",
    "# ------------------------------------------------------------\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    validation_split=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1\n",
    ")\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    DATASET_PATH,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"training\",\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_gen = train_datagen.flow_from_directory(\n",
    "    DATASET_PATH,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"validation\",\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d03eb55-550e-4fca-a963-ee4f2da4f952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 5. Charger le modèle baseline\n",
    "# ------------------------------------------------------------\n",
    "print(\"\\nChargement du modèle baseline...\")\n",
    "baseline_model = load_model(MODEL_BASELINE_PATH)\n",
    "baseline_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdbc3e6-bb21-4ea8-87c8-4e05d1e3f56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 6. Déverrouiller certaines couches (fine-tuning)\n",
    "# ------------------------------------------------------------\n",
    "print(\"\\nDégel des couches profondes pour fine-tuning...\\n\")\n",
    "fine_tune_at = 250  # laisser 250 premières couches gelées\n",
    "\n",
    "for layer in baseline_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "for layer in baseline_model.layers[fine_tune_at:]:\n",
    "    layer.trainable = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f046d8fa-fdc0-49f7-a593-6b4efec7cee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 7. Compilation\n",
    "# ------------------------------------------------------------\n",
    "baseline_model.compile(\n",
    "    optimizer=Adam(learning_rate=LR),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83933c5b-2b67-4270-9058-d1fae5d900e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 8. Callbacks pour entraîner efficacement\n",
    "# ------------------------------------------------------------\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa050f1d-584f-4b4d-ad98-5cf334a37e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 9. Entraînement du modèle fine-tuné\n",
    "# ------------------------------------------------------------\n",
    "history_finetune = baseline_model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[early_stop, reduce_lr]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b82d11-913a-45de-822a-03d29e12caaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 10. Sauvegarde modèle et historique\n",
    "# ------------------------------------------------------------\n",
    "baseline_model.save(MODEL_FINETUNED_PATH)\n",
    "with open(HISTORY_FINETUNE_PATH, \"wb\") as f:\n",
    "    pickle.dump(history_finetune.history, f)\n",
    "\n",
    "print(\"\\n✔ Modèle fine-tuné sauvegardé :\", MODEL_FINETUNED_PATH)\n",
    "print(\"✔ Historique sauvegardé :\", HISTORY_FINETUNE_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c84590c-69a8-4d23-a86f-1686710351aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 11. Visualisation\n",
    "# ------------------------------------------------------------\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history_finetune.history[\"accuracy\"], label=\"Train Acc FT\")\n",
    "plt.plot(history_finetune.history[\"val_accuracy\"], label=\"Val Acc FT\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Fine-Tuning Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history_finetune.history[\"loss\"], label=\"Train Loss FT\")\n",
    "plt.plot(history_finetune.history[\"val_loss\"], label=\"Val Loss FT\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Fine-Tuning Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
